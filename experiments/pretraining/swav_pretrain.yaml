trainer:
  _target_: pytorch_lightning.Trainer
  benchmark: True
  max_epochs: 100
  check_val_every_n_epoch: 5
  accelerator: gpu
  strategy: ddp_find_unused_parameters_true
  devices: 2
  sync_batchnorm: True
  log_every_n_steps: 1
  logger: False
    
  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      dirpath:  /mnt/data1/RadiomicsFoundationModel/checkpoints/swav_pretrain
      verbose: True
      save_last: True
      every_n_epochs: 1
      save_on_train_epoch_end: True

    - _target_: lighter.callbacks.LighterLogger
      project: ssl_radiomics_pretrain
      log_dir: ./logs
      tensorboard: False
      wandb: True
      input_type: image
      max_samples: 10

system:
  # _target_: torch.compile
  # model: 
    _target_: lighter.LighterSystem
    batch_size: 32 # Change to lower batch size if GPU memory is smaller. 
    pin_memory: True
    drop_last_batch: True # Used in SSL cases because of negatives
    num_workers: 6

    model:
      _target_: fmcib.ssl.modules.SwaV
      num_ftrs: 4096
      queue_length: 3840
      start_queue_at_epoch: 15
      n_steps_frozen_prototypes: 1
      n_prototypes: 3000
      n_queues: 2
      out_dim: 128
      backbone:
          _target_: monai.networks.nets.resnet.resnet50
          pretrained: False
          n_input_channels: 1
          widen_factor: 2
          conv1_t_stride: 2
          feed_forward: False
            
    criterion:
      _target_: fmcib.ssl.losses.SwaVLoss
      temperature: 0.1
      sinkhorn_gather_distributed: True

    optimizers:
      _target_: fmcib.optimizers.LARS
      params: "$@system#model.parameters()"
      lr: "$((@system#batch_size * @trainer#devices)/256) * 0.6" # Compute LR dynamically for different batch sizes
      weight_decay: 1.0e-6
      momentum: 0.9
    
    schedulers:
      scheduler:
        _target_: torch.optim.lr_scheduler.CosineAnnealingLR
        optimizer: "@system#optimizers"
        T_max: "$(@trainer#max_epochs) * len(@system#train_dataset)//(@system#batch_size * @trainer#devices)" # Compute total steps
      interval: "step"

    train_metrics: null
    val_metrics: "@system#train_metrics"
    test_metrics: "@system#train_metrics"
    
    train_dataset:
      _target_: fmcib.datasets.SSLRadiomicsDataset
      enable_negatives: False
      path: "data/preprocessing/deeplesion/annotations/pretrain.csv"
      orient: True
      resample_spacing: [1, 1, 1]
      transform:
        _target_: torchvision.transforms.Compose
        transforms:
          - _target_: monai.transforms.ToTensor
          - _target_: monai.transforms.AddChannel
          - _target_: monai.transforms.NormalizeIntensity
            subtrahend: -1024
            divisor: 3072
          - _target_: fmcib.transforms.MultiCrop
            high_resolution_transforms:
            - _target_: torchvision.transforms.Compose
              transforms:
                # Random Transforms begin
                - _target_: fmcib.transforms.RandomResizedCrop3D
                  size: 50
                - _target_: monai.transforms.RandAxisFlip
                  prob: 0.5
                - _target_: monai.transforms.RandHistogramShift
                  prob: 0.5
                - _target_: monai.transforms.RandGaussianSmooth
                  prob: 0.5
                - _target_: monai.transforms.SpatialPad
                  spatial_size: [50, 50, 50]
            - "%#0"
            low_resolution_transforms:
              - _target_: torchvision.transforms.Compose
                transforms:
                  # Random Transforms begin
                  - _target_: fmcib.transforms.RandomResizedCrop3D
                    scale: [0.3, 0.5]
                    size: 25
                  - _target_: monai.transforms.RandAxisFlip
                    prob: 0.5
                  - _target_: monai.transforms.RandHistogramShift
                    prob: 0.5
                  - _target_: monai.transforms.RandGaussianSmooth
                    prob: 0.5
                  - _target_: monai.transforms.SpatialPad
                    spatial_size: [25, 25, 25]
              - "%#0"
              - "%#0"
              - "%#0"
              - "%#0"
              - "%#0"

    val_dataset: null
    test_dataset: null